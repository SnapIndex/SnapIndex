{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4 embeddings\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "documents: list[str] = [\n",
    "    \"passage: Hello, World!\",\n",
    "    \"query: Hello, World!\",\n",
    "    \"passage: This is an example passage.\",\n",
    "    \"fastembed is supported by and maintained by Qdrant.\"\n",
    "]\n",
    "\n",
    "#embedding_model = TextEmbedding() #\n",
    "#embeddings: list[np.ndarray] = embedding_model.embed(documents) #\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Embedding in batches\n",
    "Small batch (8–16) → Lower memory use, but slower (more runtime calls).\n",
    "Medium batch (32–128) → Often the sweet spot on CPU.\n",
    "Large batch (256+) → Can be faster on GPUs or beefy CPUs, but risks OOM (out of memory) errors.\n",
    "\"\"\"\n",
    "embedding_model = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") # change model here : MiniLM\n",
    "embeddings = list(embedding_model.embed(documents, batch_size=64))\n",
    "print(f\"Got {len(embeddings)} embeddings\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d5df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastembed\n",
      "  Downloading fastembed-0.7.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.20 (from fastembed)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting mmh3<6.0.0,>=4.1.0 (from fastembed)\n",
      "  Downloading mmh3-5.2.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from fastembed) (2.3.3)\n",
      "Collecting onnxruntime>1.20.0 (from fastembed)\n",
      "  Using cached onnxruntime-1.22.1-cp313-cp313-macosx_13_0_universal2.whl.metadata (4.6 kB)\n",
      "Collecting pillow<12.0.0,>=10.3.0 (from fastembed)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed)\n",
      "  Downloading py_rust_stemmers-0.1.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting requests<3.0,>=2.31 (from fastembed)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<1.0,>=0.15 (from fastembed)\n",
      "  Using cached tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting tqdm<5.0,>=4.66 (from fastembed)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.20->fastembed)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.20->fastembed)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.20->fastembed)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.20->fastembed)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0,>=2.31->fastembed)\n",
      "  Using cached charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl.metadata (36 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0,>=2.31->fastembed) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3.0,>=2.31->fastembed) (2025.8.3)\n",
      "Collecting coloredlogs (from onnxruntime>1.20.0->fastembed)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>1.20.0->fastembed)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.13/site-packages (from onnxruntime>1.20.0->fastembed) (6.32.1)\n",
      "Collecting sympy (from onnxruntime>1.20.0->fastembed)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>1.20.0->fastembed)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>1.20.0->fastembed)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading fastembed-0.7.3-py3-none-any.whl (105 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading mmh3-5.2.0-cp313-cp313-macosx_11_0_arm64.whl (40 kB)\n",
      "Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Downloading py_rust_stemmers-0.1.5-cp313-cp313-macosx_11_0_arm64.whl (272 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl (205 kB)\n",
      "Using cached tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached onnxruntime-1.22.1-cp313-cp313-macosx_13_0_universal2.whl (34.3 MB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: py-rust-stemmers, mpmath, flatbuffers, tqdm, sympy, pyyaml, pillow, mmh3, loguru, humanfriendly, hf-xet, fsspec, filelock, charset_normalizer, requests, coloredlogs, onnxruntime, huggingface-hub, tokenizers, fastembed\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [fastembed]20\u001b[0m [fastembed]e-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed charset_normalizer-3.4.3 coloredlogs-15.0.1 fastembed-0.7.3 filelock-3.19.1 flatbuffers-25.2.10 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.34.4 humanfriendly-10.0 loguru-0.7.3 mmh3-5.2.0 mpmath-1.3.0 onnxruntime-1.22.1 pillow-11.3.0 py-rust-stemmers-0.1.5 pyyaml-6.0.2 requests-2.32.5 sympy-1.14.0 tokenizers-0.22.0 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")  # Using an in-process Qdrant\n",
    "## CAN BUILD CACHE\n",
    "\n",
    "docs = [\"Qdrant has Langchain integrations\", \"Qdrant also has Llama Index integrations\"]\n",
    "metadata = [\n",
    "    {\"source\": \"Langchain-docs\"},\n",
    "    {\"source\": \"Llama-index-docs\"},\n",
    "]\n",
    "ids = [42, 2]\n",
    "\n",
    "client.add(\n",
    "    collection_name=\"demo_collection\",\n",
    "    documents=docs,\n",
    "    metadata=metadata,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "search_result = client.query(\n",
    "    collection_name=\"demo_collection\",\n",
    "    query_text=\"This is a query document\"\n",
    ")\n",
    "print(search_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
